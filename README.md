## ΑΡΧΙΤΕΚΤΟΝΙΚΗ ΠΡΟΗΓΜΕΝΩΝ ΥΠΟΛΟΓΙΣΤΩΝ

### 2η Εργαστηριακή Άσκηση

#### Design Space Exploration με τον gem5 

### Βήμα 1ο

**1.** Από τα config.ini αρχεία του κάθε benchmark, βλέπουμε στο Line 15 ότι το μέγεθος της cache line είναι  **cache\_line_size=64**.  Όσον αφορά τα associativities των cache memories, έχουμε:

* Line 152: **assoc=2**, που σημαίνει 2-way set L1 Data cache associativity 
* Line 816: **assoc=2**, που σημαίνει 2-way set L1 Instruction cache associativity
* Line 1061: **assoc=8**, που σημαίνει 8-way set L2 cache associativity

Τα μεγέθη των cache memories βρίσκονται στα παρακάτω lines:

* Line 169: **size=65536**, που σημαίνει 64kB μέγεθος για την L1 Data cache
* Line 833: **size=32768**, που σημαίνει 32kB μέγεθος για την L1 Instruction cache
* Line 1078: **size=2097152**, που σημαίνει 2MB μέγεθος για την L2 cache

**2.** Για το κάθε benchmark, χρησιμοποιούμε το αντίστοιχο αρχείο stats.txt για να αντλήσουμε τις εξής πληροφορίες:

* **401.BZIP2**   
  **(i)** Line 12: **sim\_seconds=0.083718** (_χρόνος εκτέλεσης_)   
  **(ii)** Line 16: **system.cpu.cpi=1.674353** (_cycles per instruction_)  
  **(iii)** 
  * Line 124: **system.cpu.dcache.overall\_miss_rate::total=0.014248** (_συνολικό miss rate για την L1 data cache_)
  * Line 331: **system.cpu.icache.overall\_miss\_rate::total=0.000077** (_συνολικό miss rate για την L1 instruction cache_)   
  * Line 494: **system.l2.overall\_miss_rate::total=0.295243** (_συνολικό miss rate για την L2 cache_)

* **429.MCF**  
  **(i)** Line 12: **sim\_seconds=0.064937** (_χρόνος εκτέλεσης_)   
  **(ii)** Line 16: **system.cpu.cpi=1.298734** (_cycles per instruction_)  
  **(iii)** 
  * Line 124: **system.cpu.dcache.overall\_miss_rate::total=0.002079** (_συνολικό miss rate για την L1 data cache_)
  * Line 332: **system.cpu.icache.overall\_miss\_rate::total=0.023610** (_συνολικό miss rate για την L1 instruction cache_)   
  * Line 496: **system.l2.overall\_miss_rate::total=0.055082** (_συνολικό miss rate για την L2 cache_)

* **456.HMMER**   
  **(i)** Line 12: **sim\_seconds=0.059390** (_χρόνος εκτέλεσης_)   
  **(ii)** Line 16: **system.cpu.cpi=1.187803** (_cycles per instruction_)  
  **(iii)** 
  * Line 124: **system.cpu.dcache.overall\_miss_rate::total=0.001628** (_συνολικό miss rate για την L1 data cache_)
  * Line 348: **system.cpu.icache.overall\_miss_rate::total=0.000212** (_συνολικό miss rate για την L1 instruction cache_)   
  * Line 512: **system.l2.overall\_miss_rate::total=0.078296** (_συνολικό miss rate για την L2 cache_)

* **458.SJENG**   
  **(i)** Line 12: **sim\_seconds=0.513811** (_χρόνος εκτέλεσης_)   
  **(ii)** Line 16: **system.cpu.cpi=10.276223** (_cycles per instruction_)  
  **(iii)** 
  * Line 124: **system.cpu.dcache.overall\_miss_rate::total=0.121831** (_συνολικό miss rate για την L1 data cache_)
  * Line 329: **system.cpu.icache.overall\_miss\_rate::total=0.000020** (_συνολικό miss rate για την L1 instruction cache_)   
  * Line 491: **system.l2.overall\_miss_rate::total=0.999972** (_συνολικό miss rate για την L2 cache_)

* **470.LBM**   
  **(i)** Line 12: **sim\_seconds=0.174771** (_χρόνος εκτέλεσης_)   
  **(ii)** Line 16: **system.cpu.cpi=3.495428** (_cycles per instruction_)  
  **(iii)** 
  * Line 124: **system.cpu.dcache.overall\_miss_rate::total=0.060972** (_συνολικό miss rate για την L1 data cache_)
  * Line 331: **system.cpu.icache.overall\_miss\_rate::total=0.000093** (_συνολικό miss rate για την L1 instruction cache_)   
  * Line 493: **system.l2.overall\_miss_rate::total=0.999944** (_συνολικό miss rate για την L2 cache_)

Χρησιμοποιήσαμε το Excel για να κατασκευάσουμε τα γραφήματα, ώστε να συγκρίνουμε τα διάφορα μεγέθη. 

Από το γράφημα Simulation Time (seconds), βλέπουμε ότι το benchmark που έκανε με διαφορά τον περισσότερο χρόνο να ολοκληρωθεί (πάντα μέχρι το όριο των εντολών που του δώσαμε) είναι το **458.sjeng**. Φαίνεται, ταυτόχρονα, ότι και στο CPI και στο Cache Miss Rates γράφημα, για το 458.sjeng benchmark, έχουμε πολλά cycles per instruction, εφόσον παρατηρείται υψηλό ποσοστό miss στις cache μνήμες, κι άρα ο επεξεργαστής αργεί να πάρει εντολές και δεδομένα.

Επίσης, παρατηρούμε ότι, σε όλα τα benchmarks, το μεγαλύτερο miss rate εμφανίζεται πάντα στην L2 cache.

**3.** Το default --cpu-clock είναι 2GHz.

Αφού τρέξαμε το benchmark 401.bzip2, βάζοντας το flag --cpu-clock=2GHz (αν και, όπως είπαμε, δεν χρειάζεται εφόσον αυτή είναι η default τιμή), ψάξαμε στο stats.txt αρχείο και βρήκαμε τις εξής πληροφορίες για το ρολόι: 

* Line 92: Βλέπουμε ότι το ανώτατου level clock domain χρονίζεται στο **1GHz**, που είναι και η default τιμή.
* Line 463: Το cpu clock domain χρονίζεται στα **2GHz**. Το ρολόι αυτό αφορά block που τρέχουν σε ταχύτητες CPU.

Την ίδια συμπεριφορά παρατηρήσαμε και εκτελώντας το benchmark 429.mcf με το ίδιο flag.

Στην συνέχεια, τρέξαμε το benchmark 456.hmmer, χρονίζοντας το cpu clock στο 1GHz (αντί του default 2GHz), με το flag --cpu-clock=**1GHz**. Συγκρίναμε τα δύο διαφορετικά stats.txt που προέκυψαν, και πέραν του χαμηλότερου CPI με την μείωση της συχνότητας του ρολογιού των επεξεργαστών, παρατηρήσαμε τα εξής:  
		
(Τα παρακάτω αποτελέσματα παρουσιάζονται για system\_clock=1GHz // system\_clock=2GHz)

* Line 12: **sim\_seconds=0.118517** // **sim\_seconds=0.059390**
* Line 92: **system.clk\_domain.clock=1000** // **system.clk\_domain.clock=1000**
* Line 481: **system.cpu\_clk\_domain.clock=1000** // **system.cpu\_clk\_domain.clock=500**

Άρα καταλήγουμε ότι **με το flag --cpu-clock χρονίζουμε το ρολόι που αφορά τα objects των επεξεργαστών**. Αυτό σημαίνει ότι, προσθέτοντας άλλον έναν επεξεργαστή στο σύστημα, αυτός θα λειτουργήσει με συχνότητα που δόθηκε με το flag --cpu-clock, και η τιμή του θα φαίνεται στην παράμετρο system.cpu\_clk\_domain.clock. Αν ο κάποιος επεξεργαστής δούλευε σε διαφορετική συχνότητα από τους υπόλοιπους, θα εμφανίζονταν διάφορες αστάθειες στην λειτουργία του συστήματος.

Όσον αφορά το scaling, αν υποδιπλασιάσουμε, για παράδειγμα, την συχνότητα του ρολογιού, θα έπρεπε να διπλασιαστεί και ο χρόνος εκτέλεσης. Παρ' όλα αυτά, βλέπουμε ότι δεν ισχύει ακριβώς αυτή η αντίστροφη αναλογία (φαίνεται στο αρχείο Excel, με την σύγκριση 9ου και 10ου test). Αυτό συμβαίνει λόγω αστοχιών που πραγματοποιούνται με την κάθε εκτέλεση benchmark.

### Βήμα 2ο

**1.** Σκοπός μας ήταν να πραγματοποιήσουμε πολλά tests για κάθε benchmark, αλλάζοντας κάθε φορά και μια διαφορετική παράμετρο, ώστε να δούμε σε γενικές γραμμές τι επιρροή έχουν στην εκτέλεσή τους.

Καταγράψαμε σε ένα Excel worksheet όλα τα αποτελέσματα που μας αφορούσαν σε κάθε test που εκτελέσαμε για κάθε benchmark. Για κάθε αποτέλεσμα, κάνουμε σύγκριση με το αμέσως προηγούμενο test, και κρίνουμε αν η αλλαγή που δοκιμάσαμε βελτίωσε (πράσινο), χειροτέρεψε (κόκκινο), ή δεν επηρέασε (κίτρινο) τα αποτελέσματά μας.

Σε γενικές γραμμές, ο τρόπος σκέψης που ακολουθήσαμε είναι ο εξής:

* Όπου βλέπαμε υψηλό miss rate, δοκιμάζαμε να αλλάξουμε τα μεγέθη και τα assosiativities των cache memories.
* Πειράζαμε την συχνότητα του CPU clock για να βρούμε κάποια καλή ισορροπία μεταξύ του χρόνου εκτέλεσης και του CPI (_ομολογουμένως, στην συνέχεια συνειδητοποιήσαμε ότι το ρολόι δεν είναι ανάμεσα στις παραμέτρους με τις οποίες πειραματιζόμαστε, γι' αυτό και στο τελευταίο test επαναφέραμε την default τιμή του CPU clock_)

**2.** Τα γραφήματα στα οποία φαίνονται τα διαφορετικά αποτελέσματα για τις διαφορετικές τιμές των παραμέτρων φαίνονται στον φάκελο Step 2.

### Βήμα 3ο

Βλέποντας, τώρα, τις αλλαγές που επέφεραν οι πειραματισμοί μας στην επίδοση των benchmarks, προσπαθήσαμε να αποδώσουμε κάποιο ποσοστό επίδρασης σε κάθε παράμετρο. Οι τιμές στις οποίες καταλήξαμε φαίνονται στο Excel worksheet, πάνω δεξιά.

Κάπως έτσι, κατασκευάσαμε μια συνάρτηση κόστους για το κάθε benchmark, όπου κάθε παράμετρος έχει κι από έναν συντελεστή βαρύτητας (που είναι το ποσοστό το οποίο θεωρήσαμε αυθαίρετα).

Οι συναρτήσεις κόστους είναι:

* **401.bzip2**: 0.18\*(l1d\_size) + 0.16*(l1i\_size) + 0.18\*(l2\_size) + 0.09\*(l1i\_assoc) + 0.15\*(l1d\_assoc) + 0.16\*(l2\_assoc) + 0.08\*(cacheline_size)

* **429.mcf**: 0.09\*(l1d\_size) + 0.2*(l1i\_size) + 0.08\*(l2\_size) + 0.07\*(l1i\_assoc) + 0.4\*(l1d\_assoc) + 0.06\*(l2\_assoc) + 0.1\*(cacheline_size)

* **456.hmmer**: 0.28\*(l1d\_size) + 0.28*(l1i\_size) + 0.28\*(l2\_size) + 0.01\*(l1i\_assoc) + 0.14\*(l1d\_assoc) + 0.00\*(l2\_assoc) + 0.01\*(cacheline_size)

* **458.sjeng**: 0.04\*(l1d\_size) + 0.16*(l1i\_size) + 0.09\*(l2\_size) + 0.05\*(l1i\_assoc) + 0.1\*(l1d\_assoc) + 0.04\*(l2\_assoc) + 0.52\*(cacheline_size)

* **470lbm**: 0.015\*(l1d\_size) + 0.06\*(l1i\_size) + 0.1\*(l2\_size) + 0.00\*(l1i\_assoc) + 0.04\*(l1d\_assoc) + 0.08\*(l2\_assoc) + 0.57\*(cacheline_size)

Στην συνέχεια, ονομάσαμε x ένα αυθαίρετο κόστος (έστω ευρώ €), και το αναθέσαμε σε κάθε παράμετρο, αναλογικά με το πόσο θεωρούμε ότι κοστίζει η καθεμιά:

Κόστη:

* l1d\_size : 4x
* l1i\_size : 3x
* l2\_size : x
* l1i\_assoc : 1.5x
* l1d\_assoc : 1.5x
* l2\_assoc : 0.5x
* cacheline\_size: 5x

**401.bzip2**: Βλέπουμε ότι τα l1d\_size και l2\_size έχουν ίδιο συντελεστής βαρύτητας (όσον αφορά την απόδοση του benchmark), ξέρουμε όμως ότι η κατασκευή της L1 cache είναι ακριβότερη από την κατασκευή της L2 cache. Για τον λόγο αυτό, θα αυξήσουμε αρκετά το μέγεθος της L2, συγκριτικά με αυτό της L1 Data.  
 Έπειτα έχουμε το κόστος του l1i_size, το οποίο επιδρά σε μικρότερο βαθμό από τα προαναφερθέντα, οπότε θα κανονίσουμε το l1i\_size να είναι μικρότερο του l1d\_size, και προφανώς του l2\_size.  
Όσον αφορά τα associativities, μεγαλύτερη θετική επίδραση έχει αυτό της L2, οπότε θα δώσουμε μεγάλη βάση σε αυτό και θα το μειώσουμε αρκετά. Σε αυτήν την περίπτωση, ο χρόνος εκτέλεσης αυξάνεται ελάχιστα, αλλά είναι ένα μικρό trade-off για καλύτερο CPI. Αντίστοιχα, θα μειώσουμε τα associativities των L1 instruction και data cache.  
Τέλος, αποδείχθηκε ότι το cacheline\_size επηρέασε ελάχιστα την απόδοση του benchmark, οπότε, ειδικά λαμβάνοντας υπόψη το κόστος που έρχεται με την αύξησή του, θα του δώσουμε μια σχετική χαμηλή τιμή.

Με την ίδια λογική κινηθήκαμε και στα υπόλοιπα benchmarks. Για κάθε παράμετρο, έπρεπε να συγκρίνουμε επίδραση και κόστος και να πετύχουμε μια καλή ισορροπία ανάμεσα στα δύο.

### ΠΗΓΕΣ

Οι πηγές από τις οποίες αντλήσαμε πληροφορίες είναι:

1. [https://www.gem5.org/documentation/learning_gem5/part1/cache_config/](https://www.gem5.org/documentation/learning_gem5/part1/cache_config/)
2. [http://learning.gem5.org/book/part1/example_configs.html](http://learning.gem5.org/book/part1/example_configs.html)
3. [http://csillustrated.berkeley.edu/PDFs/handouts/cache-3-associativity-handout.pdf](http://csillustrated.berkeley.edu/PDFs/handouts/cache-3-associativity-handout.pdf)
4. [https://www.gatevidyalay.com/cache-line-cache-line-size-cache-memory/](https://www.gatevidyalay.com/cache-line-cache-line-size-cache-memory/)
5. [http://home.ku.edu.tr/comp303/public_html/Lecture15.pdf](http://home.ku.edu.tr/comp303/public_html/Lecture15.pdf)
6. [https://en.wikipedia.org/wiki/Cycles_per_instruction](https://en.wikipedia.org/wiki/Cycles_per_instruction)

***

### ΚΡΙΤΙΚΗ

Το 2ο εργαστήριο, σε γενικά πλαίσια, ήταν αρκετά διαφωτιστικό όσον αφορά την λειτουργιά του επεξεργαστή: ο πειραματισμός μας με τις διάφορες παραμέτρους και η μετέπειτα μελέτη των αποτελεσμάτων ήταν πάρα πολύ κατατοπιστική και ανέλπιστα ενστικτώδης. Ενδιαφέρουσα ήταν και η γνωριμία μας με τα διαφορετικά benchmarks και το τι προσομοιάζει το κάθενα.  
Το 3ο βήμα της εργασίας ήταν και το πιο απαιτητικό, εξαιτίας της κριτικής σκέψης και των βιβλιογραφικών γνώσεων που ζητούσε - κάπως έτσι όμως οδηγηθήκαμε στην καλύτερη εξοικείωση με έναν επεξεργαστή και την κατανόηση του trade-off που ορισμένες φορές χρειάζεται στην σχεδίασή του.  
Το PDF του εργαστηρίου είχε ένα λάθος που μας εκτόπισε αρκετά: ως default τιμή του CPU clock θεωρείτο το 1GHz, ενώ στην πραγματικότητα είναι 2GHz. Αργότερα μάθαμε ότι η τιμή αυτή είναι η default για παλιότερο μοντέλο. Επιπλέον, το 456.hmmer benchmark δεν μπορούσε να γίνει compile στην έκδοση 20.04.

Αυτό που μας προβλημάτισε περισσότερο ήταν η κακή διαχείριση του χρόνου του εργαστηρίου. Ευτυχώς η ομάδα μας εξετάστηκε μέσα στα χρονικά πλαίσια (17:00-20:00), ωστόσο μάθαμε από συναδέλφους ότι υπήρξαν καθυστερήσεις μέχρι και τις 21:00. Επιπλέον, θεωρούμε ότι δεν έγινε σαφές μέχρι ποιο σημείο της εργασίας πρέπει να έχουμε φτάσει την μέρα του εργαστηρίου: αν οφείλουμε, όπως μας εξηγήθηκε την ώρα της εξέτασής μας στο 2ο εργαστήριο, να παρουσιάσουμε ολοκληρωμένα τα αποτελέσματα και τις απαντήσεις μας σε όλα τα ερωτήματα της εργασίας, τότε η αναμονή μας στα break out rooms καθίσταται άσκοπη. Μία πιθανή λύση γι' αυτό είναι η κάθε ομάδα να εξετάζεται συγκεκριμένη ώρα, πράγμα που θα βοηθούσε και εσάς να προγραμματίζετε σχετικά ισομερώς τον χρόνο που αφιερώνετε στο κάθε break out room. Βέβαια, τα παραπάνω δικαιολογούνται στα πλαίσια της online διεξαγωγής του εργαστηρίου, που κατανοούμε ότι δεν θεωρείται το νορμάλ κι αυτό που είχατε εξαρχής υπόψη.
